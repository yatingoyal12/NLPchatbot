{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48a94b4a-6e9d-43b0-a65b-8b094721becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identity_0</td>\n",
       "      <td>from human, value Ive been feeling so sad and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>identity_0</td>\n",
       "      <td>Remember to be kind to yourself and celebrate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identity_1</td>\n",
       "      <td>from human, value Hi, Im feeling really scared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>identity_1</td>\n",
       "      <td>from human, value Thank you for reminding me o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>identity_2</td>\n",
       "      <td>from human, value Hey, I hope youre doing well...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              chunk\n",
       "0  identity_0  from human, value Ive been feeling so sad and ...\n",
       "1  identity_0  Remember to be kind to yourself and celebrate ...\n",
       "2  identity_1  from human, value Hi, Im feeling really scared...\n",
       "3  identity_1  from human, value Thank you for reminding me o...\n",
       "4  identity_2  from human, value Hey, I hope youre doing well..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"chat_data.csv\"  # Adjust if file is zipped\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Example of cleaning a single conversation\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the text by:\n",
    "    - Removing unwanted characters\n",
    "    - Handling extra whitespaces\n",
    "    \"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)  # Remove special characters\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_conversations'] = df['conversations'].apply(clean_text)\n",
    "\n",
    "# Splitting large texts into smaller chunks (e.g., 512 tokens)\n",
    "def chunk_text(text, chunk_size=512):\n",
    "    \"\"\"\n",
    "    Splits text into smaller chunks of a defined size, \n",
    "    while respecting sentence boundaries.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)  # Split into sentences\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_length = len(sentence.split())  # Word count in the sentence\n",
    "        if current_length + sentence_length > chunk_size:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(sentence)\n",
    "        current_length += sentence_length\n",
    "\n",
    "    # Add any remaining chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking\n",
    "df['conversation_chunks'] = df['cleaned_conversations'].apply(chunk_text)\n",
    "\n",
    "# Flatten the DataFrame: each chunk becomes a row\n",
    "flattened_data = []\n",
    "for idx, row in df.iterrows():\n",
    "    for chunk in row['conversation_chunks']:\n",
    "        flattened_data.append({'id': row['id'], 'chunk': chunk})\n",
    "\n",
    "chunk_df = pd.DataFrame(flattened_data)\n",
    "\n",
    "# Review preprocessed data\n",
    "chunk_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc2c803-3d6c-485f-9172-2fd6fac94355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b75cb1c700454da468c75c62d4b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/6135 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built successfully with 196319 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load model with GPU support if available\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Batch encode chunks\n",
    "chunks = chunk_df['chunk'].tolist()\n",
    "embeddings = embedding_model.encode(chunks, batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# Reduce dimensions using PCA (Optional: Use `whiten=True` for normalized output)\n",
    "pca = PCA(n_components=128, whiten=True)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Build a FAISS index with IVF for scalable approximate search\n",
    "nlist = 100  # Number of clusters for inverted indexing\n",
    "quantizer = faiss.IndexFlatL2(128)  # Base index for clustering\n",
    "faiss_index = faiss.IndexIVFFlat(quantizer, 128, nlist, faiss.METRIC_L2)\n",
    "\n",
    "# Train the index on reduced embeddings\n",
    "if not faiss_index.is_trained:\n",
    "    faiss_index.train(reduced_embeddings)\n",
    "\n",
    "# Add vectors to the index\n",
    "faiss_index.add(reduced_embeddings)\n",
    "\n",
    "# Optional: Save the index for reuse\n",
    "faiss.write_index(faiss_index, \"faiss_index_ivf.index\")\n",
    "\n",
    "print(f\"FAISS index built successfully with {faiss_index.ntotal} vectors.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ae92fa-4214-4581-81e5-115235c62de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_relevant_chunks(query, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve the top-k relevant chunks based on the query.\n",
    "    \"\"\"\n",
    "    # Encode the query\n",
    "    query_embedding = embedding_model.encode([query], convert_to_numpy=True)\n",
    "    \n",
    "    # Reduce dimensions using the same PCA used earlier\n",
    "    query_embedding_reduced = pca.transform(query_embedding)\n",
    "    \n",
    "    # Search the FAISS index\n",
    "    distances, indices = faiss_index.search(query_embedding_reduced.astype(np.float32), k)\n",
    "    \n",
    "    # Retrieve the corresponding chunks\n",
    "    results = [chunk_df.iloc[idx]['chunk'] for idx in indices[0]]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b4db61-517b-4290-bd83-ecc7fb2977cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from human, value I like the idea of selfcompassion, but its hard to convince myself that I deserve it. Challenging negative thoughts might be difficult, but Im willing to give it a shot. As for finding joy, its been a while since Ive truly felt happy. How do I even begin? from gpt, value Starting small is key, Charlie. Begin by acknowledging one positive thing about yourself each day, no matter how small. Take time to appreciate your strengths and accomplishments, however insignificant they may seem. Its through these small steps that you can gradually invite joy back into your life. Remember, Im here to guide and support you throughout this journey. from human, value Thank you, Alex. It means a lot to have someone who believes in me when I struggle to believe in myself. Im scared, but Im willing to give therapy a chance. from gpt, value Charlie, Im here for you every step of the way. It takes strength and courage to confront our inner demons and work towards healing. Together, we can create a safe space for you to rebuild your selfesteem and find the happiness you deserve.', 'from gpt, value Thats a beautiful way to find solace, Charlie. Creative expressions can be incredibly therapeutic, allowing you to process your emotions and find moments of peace. As you continue exploring these activities, remember to be gentle with yourself and acknowledge any small victories along the way. How would you like to further nurture your healing journey? from human, value I think one area Id like to focus on is selfcompassion. Instead of beating myself up for the mistakes I made in my past relationship, I want to learn to forgive myself and believe that I deserve happiness. Practicing selfcompassion feels like a crucial step towards rebuilding my life. from gpt, value Thats a significant realization, Charlie. Selfcompassion is a powerful tool for healing and moving forward. It allows us to acknowledge our pain and embrace our humanity, understanding that we all make mistakes. By cultivating selfforgiveness and selflove, you can create a solid foundation for a brighter future. Remember, youre not alone in this journey. from human, value Thank you, Alex. Your support means the world to me. It feels empowering to know that I have someone in my corner, cheering me on as I navigate this difficult path towards healing and rebuilding my life. from gpt, value Youre very welcome, Charlie. Its an honor to accompany you on this journey. Together, we will work towards finding hope and creating a life filled with love, joy, and meaningful connections. Remember, every step you take, no matter how small, is a step towards reclaiming your happiness. Im here for you every step of the way.', 'from human, value I think, Alex, it will take time and selfcompassion to rebuild my sense of self. I want to focus on the aspects of me that remain unchanged  my values, my relationships. Its about finding new ways to express myself and discovering resilient parts of my identity. from gpt, value Thats a beautiful and empowering perspective, Charlie. Nurturing selfcompassion and focusing on the unshakable aspects of your being can be instrumental in reclaiming your sense of self. How can you begin to integrate these ideas into your life moving forward? from human, value I think, Alex, I will start by practicing selfcompassion through daily affirmations and gratitude. I will also seek out support groups or online communities where I can connect with others facing similar health challenges. By doing so, I hope to find strength in shared experiences. from gpt, value Charlie, your determination to embrace selfcompassion and seek support is commendable. Building connections with others who can relate to your journey can be incredibly empowering. Remember, healing is not a linear process, and there will be ups and downs. But I believe in your ability to navigate this path with resilience. from human, value Thank you, Alex, for your unwavering support and guidance. I leave this conversation feeling hopeful and inspired to embark on this journey of selfdiscovery and healing. I am determined to rise above the challenges I face and embrace the possibilities that lie ahead. from gpt, value Charlie, it has been an honor to be part of your journey. Remember, I am here to support you every step of the way. Stay hopeful, be gentle with yourself, and never underestimate your own strength. You deserve healing, and I have unshakable faith in your ability to find it.', 'Im willing to try anything that may help me find some relief and regain my sense of selfworth. The constant sadness and anxiety have become so overwhelming that I find it hard to focus on anything else. from gpt, value That willingness to explore new coping strategies is a remarkable step, Charlie. One approach could be focusing on selfcare activities that bring you joy and peace. Engaging in activities like exercise, deep breathing exercises, journaling, or spending time in nature can help alleviate the symptoms of depression and anxiety. Additionally, practicing selfcompassion and challenging negative selftalk can be powerful tools in rebuilding selfesteem. How does that sound to you? from human, value Thank you for your suggestions, Alex. I appreciate your guidance. Engaging in selfcare activities and adopting selfcompassion practices resonate with me. I believe dedicating time to myself and challenging my negative thoughts could make a significant positive impact in my journey towards healing. from gpt, value Youre welcome, Charlie. Im glad the suggestions resonate with you. Remember, healing takes time, and its important to be patient with yourself along the way. Acknowledge your progress, no matter how small, and celebrate your resilience. Im here to support you throughout this journey. Is there anything else you would like to discuss or explore in our session today?', 'from human, value By embracing and nurturing my empathy, I can develop more meaningful connections with others. When I see the positive impact I can have on someones life, it strengthens my belief in my own worthiness and value as a person. from gpt, value Thats a powerful realization, Charlie. By channeling your empathy and making a difference in other peoples lives, youre also nurturing your own selfesteem. Its an interconnected process of giving and receiving. How else can you foster a positive relationship with yourself? from human, value I believe practicing selfcompassion is crucial. Instead of dwelling on my mistakes, I can remind myself that we all make errors and that its an opportunity for growth. By treating myself with kindness and understanding, I can rebuild my selfesteem from within. from gpt, value Thats a profound insight, Charlie. Selfcompassion is vital in nurturing selfesteem. Remembering that we are all imperfect beings allows us to forgive ourselves and embrace our strengths and weaknesses. How do you envision implementing selfcompassion in your daily life? from human, value I think incorporating selfcare activities such as meditation, journaling, and spending time in nature will help me reconnect with myself and cultivate selfcompassion. By prioritizing my wellbeing, Ill be better equipped to navigate challenging emotions and situations. from gpt, value Thats an excellent plan, Charlie. Selfcare and selfcompassion are powerful tools for healing and growth. As we wrap up our session for today, I encourage you to take these insights and strategies with you. Remember, the journey to rebuilding selfesteem is a process that requires patience and selflove. from human, value Thank you, Alex. I already feel a sense of hope and renewal from our conversation today. I will continue to work on healing and embracing my own worthiness. Im grateful for your guidance and support. from gpt, value Im glad to hear that, Charlie. Remember, you are worthy of forgiveness, growth, and selfcompassion. Im here for you every step of the way. Take care of yourself, and Ill see you in our next session.']\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I reset my password?\"\n",
    "relevant_chunks = retrieve_relevant_chunks(query)\n",
    "print(relevant_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf04a0b9-a587-44be-9802-bef5fb9d7bc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-hf.\n401 Client Error. (Request ID: Root=1-674faabd-0be79050114ff4f47331a8da;83920360-085e-454b-9bcd-dadefda39b37)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    404\u001b[0m         path_or_repo_id,\n\u001b[0;32m    405\u001b[0m         filename,\n\u001b[0;32m    406\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    407\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    408\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    409\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    410\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    411\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    412\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    413\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    414\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    415\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m    863\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    864\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m    867\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    868\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    869\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m    872\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m    873\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    874\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    875\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m    877\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    878\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    879\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1483\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1377\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[0;32m   1378\u001b[0m     )\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1297\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1298\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1299\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1300\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1301\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1302\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1303\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1304\u001b[0m )\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:277\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 277\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    278\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    279\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    280\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    282\u001b[0m     )\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\file_download.py:301\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 301\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:423\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    420\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    422\u001b[0m     )\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-674faabd-0be79050114ff4f47331a8da;83920360-085e-454b-9bcd-dadefda39b37)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-hf is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load model and tokenizer for Falcon\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adjust to your desired model path\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      6\u001b[0m llm_model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create Hugging Face pipeline for text generation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:877\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    875\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 877\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    878\u001b[0m             pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1017\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1014\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1015\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1017\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1018\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1019\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\configuration_utils.py:574\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 574\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\configuration_utils.py:633\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    634\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    635\u001b[0m         configuration_file,\n\u001b[0;32m    636\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    637\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    638\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    639\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    640\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    641\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    642\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    643\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    644\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    645\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\ANACONDA\\Lib\\site-packages\\transformers\\utils\\hub.py:421\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[1;32m--> 421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-2-7b-hf.\n401 Client Error. (Request ID: Root=1-674faabd-0be79050114ff4f47331a8da;83920360-085e-454b-9bcd-dadefda39b37)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/config.json.\nAccess to model meta-llama/Llama-2-7b-hf is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load model and tokenizer for Falcon\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"  # Adjust to your desired model path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Create Hugging Face pipeline for text generation\n",
    "llm_pipeline = pipeline(\"text-generation\", model=llm_model, tokenizer=tokenizer)\n",
    "\n",
    "# Define your RAG pipeline here\n",
    "def rag_pipeline(query):\n",
    "    \"\"\"\n",
    "    RAG pipeline:\n",
    "    1. Retrieve relevant context chunks.\n",
    "    2. Use the LLM to generate a response using the retrieved context.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks (implement `retrieve_relevant_chunks` function as per your code)\n",
    "    context = retrieve_relevant_chunks(query)\n",
    "    context_str = \"\\n\".join(context)\n",
    "    \n",
    "    # Formulate a prompt\n",
    "    prompt = f\"Context: {context_str}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_pipeline(prompt, max_length=200, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Test the RAG pipeline\n",
    "response = rag_pipeline(\"How do I reset my password?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b073e60-f92f-43f7-8883-6ae09ec38108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
